{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you ever wondered how computers or ordinary calculators determine the square root of a number? After all, most programming languages only provide the standard arithmatical operators like `+`, `-`, or `*`. In this tutorial, we learn how the underlying algorithm works behind the `math.sqrt` function in Python's Standard Library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mathematical grounding lies in Newton's Method, a numerical method to approximate the roots of continuous functions. Below is a lecture by MIT's professor of linear algebra [Gilbert Strang](http://math.mit.edu/~gs/) outlining the basic idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"U0xlKuFqCuI\", width=\"80%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, Newton's Method starts by guessing a root of a function and then improving that guess by linearly approximating the function. As we will see, all we need to supply is a Python function that returns the $y$ value of a mathematical function $y = f(x)$ for a given $x_0$ and another Python function that does the same for the derivative thereof. Newton's method can be regarded as a framework that takes our user-defined functions and finds  the roots of $f$, i.e., the set  $\\{x \\in \\mathbb{R}: f(x) = 0 \\}$. We build up the method step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Functions & Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following defines a helper function that plots several functions we pass to it. We need the third-party library [matplotlib](https://matplotlib.org/) which we can install with the command-line tool `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disregarding the default arguments (that only define the part of the $xy$-plane shown) we can call `plot()` like so: `plot(f1, f2, ...)`. `f1`, `f2`, and so on are references to function objects that expect a single argument `x` and return the corresponding value $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(*functions, x_min=-3, x_max=3, y_min=-10, y_max=10, granularity=0.1, ax=None):\n",
    "    n = int((x_max - x_min) / granularity) + 1\n",
    "    xs = [x_min + x * granularity for x in range(n)]\n",
    "    if ax:\n",
    "        ax.clear()\n",
    "    else:\n",
    "        ax = plt.subplot()\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "    ax.plot(xs, [0 for x in xs], color=\"black\")\n",
    "    for f in functions:\n",
    "        ax.plot(xs, [f(x) for x in xs]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the following function $f_1$ as a simple example:\n",
    "\n",
    "$f_1(x) = x^3 - x + 3$\n",
    "\n",
    "We can translate it into Python as function `f1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    return ...  # put an arithmetic expression here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the derivative, we first need to do the work manually (computers can not do that by themselves):\n",
    "\n",
    "$\\frac{d}{dx} f_1(x) = f'_1(x) = 3x^2 - 1$\n",
    "\n",
    "Then, we can also translate this into a Python function `df1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df1(x):\n",
    "    return ...  # put an arithmetic expression here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(f1, df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaÃ¯ve Guessing\n",
    "\n",
    "We can now guess where $f_1$ crosses $0$ by looking at the plot but this results in tedious work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(-1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(-1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(-1.67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Approximations\n",
    "\n",
    "Given a function and its derivative we can find an approximation for the $y$ value at an $x_1$ given an $x_0$ and the corresponding $y_0 = f(x_0)$ like so:\n",
    "\n",
    "$y_1 \\approx f(x_0) + f'(x_0) * (x_1 - x_0)$\n",
    "\n",
    "Let's write a function that takes a mathematical function, its derivative, and $x_0$ and $x_1$ as arguments and returns an estimate for $y_1$ according to this rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx(func, deriv, x0, x1):\n",
    "    return func(x0) + ...  # complete the approximation with an arithmetic expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`approx()` only returns an approximation for a single point $x_1$ and takes four arguments. For example, knowing that $f_1(-1) = 3$ and $f'_1(-1) = 2$, we can obtain an estimate for $x_1 = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx(f1, df1, -1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such approximations of individual points do not seem of great value at first but visualizing the approximation rule as a **tangent line** at $x_0$ helps us understand how we can improve the approximations further below.\n",
    "\n",
    "However, in order to plot a tangent line at $x_0$, we actually need some function that only expects a single `x` as its argument. Otherwise, `plot()` does not know how to use that function.\n",
    "\n",
    "We use the following \"trick\" where an outer function `create_tangent()` takes the arguments `func`, `deriv`, and `x0` and return an inner and \"dynamically\" defined function `tangent()` that only has one argument `x` and that just returns the approximate value for that `x`. The latter can be used for plotting tangents.\n",
    "\n",
    "When we refer to `func`, `deriv`, and `x0` in the inner function, Python remembers their values even after the call to `create_tangent()` is finished. The technical term for this is [closure](https://en.wikipedia.org/wiki/Closure_%28computer_programming%29) as the outer function \"closes\" the inner function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tangent(func, deriv, x0):\n",
    "    def tangent(x):\n",
    "        return ...  # call the correct function with four arguments\n",
    "    return tangent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tan1 = create_tangent(f1, df1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tan1` is really just a reference to a function object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tan1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(f1, tan1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Educated Guessing\n",
    "\n",
    "Just like before, we start with a somewhat \"random\" guess, like $x_0 = -1$. We refer to $x_0$ as `guess` in the following to avoid confusion with the `x0` arguments in some of the other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1(guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are interested in finding the roots of a function, we can plug in $0$ for $y_1$:\n",
    "\n",
    "$0 \\approx f(x_0) + f'(x_0) * (x_1 - x_0)$\n",
    "\n",
    "Then, after rearranging the terms, we can find a better guess, by \"optimizing\" the $x_1$:\n",
    "\n",
    "$x_1 = x_0 - \\frac{f(x_0)}{f'(x_0)}$\n",
    "\n",
    "Let's translate this into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_guess(func, deriv, x0):\n",
    "    return ...  # put an arithmetic expression here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_guess(f1, df1, guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's capture these return values and then repeat the guessing process a couple of more times. $x_1$ then becomes $x_0$ in the next iteration. Also, we use `create_tangent()` and `plot()` to visualize the updated versions of the tangent line. For convenience, we compose these two functions into a new function `plot_tangent()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tangent(func, deriv, x0, **kwargs):\n",
    "    plot(func, create_tangent(func, deriv, x0), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our random guess is quite far away from $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess, f1(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tangent(f1, df1, guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the 1st iteration, we are actually further away from the root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = next_guess(f1, df1, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess, f1(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tangent(f1, df1, guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the 2nd iteration, we seem to be getting where we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = next_guess(f1, df1, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess, f1(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tangent(f1, df1, guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the 3rd iteration, we have almost made it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = next_guess(f1, df1, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess, f1(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tangent(f1, df1, guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the 4th iteration, we can hardly tell the difference from $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = next_guess(f1, df1, guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess, f1(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tangent(f1, df1, guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first Search Algorithm\n",
    "\n",
    "How can we tell if we have reached $0$ close enough? What happens if our initial random guess is way off? Does this procedure always terminate or might we end up in an infinite loop?\n",
    "\n",
    "Let us define a `show_search()` function that takes the arguments `func`, `deriv`, `guess`, and `epsilon` and implements a the iterative search procedure with a `while` loop and shows the tangent's development over time. `epsilon` is the fault tolerance and defaults to $10^{-15}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_search(func, deriv, guess, epsilon=1e-15, **kwargs):\n",
    "\n",
    "    # only for interactive plotting\n",
    "    kwargs.update(ax=plt.subplot())\n",
    "    n_iter = 0\n",
    "\n",
    "    # Iterate until the guess is good enough\n",
    "    while ... > epsilon:  # compare the absolute error to the allowed fault tolerance\n",
    "\n",
    "        # only for interactive plotting\n",
    "        print(\"Guess: {:30.20f}   (Iteration #{})\".format(guess, n_iter))\n",
    "        plot_tangent(f1, df1, guess, **kwargs)\n",
    "        n_iter += 1\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        sleep(0.5)\n",
    "\n",
    "        guess = ...  # call the correct function to obtain the next educated guess\n",
    "\n",
    "    # only for interactive plotting\n",
    "    print(\"Final: {:30.20f}   (Iteration #{})\".format(guess, n_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_search(f1, df1, -1, x_min=-5, x_max=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the initial guess is way off, we can still be lucky and the search finishes fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_search(f1, df1, -1000, x_min=-10, x_max=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our initial guess is near a flat part of $f$, the next guesses will \"overshoot\" the actual root by a lot and then has trouble converging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_search(f1, df1, -0.577, x_min=-10, x_max=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Search\n",
    "\n",
    "Let us finalize our iterative search procedure with a function `local_search()` that takes the same arguments as `show_search()` and a `max_iter` argument defaulting to $1000$ that prevents the search to go into an infinite loop. The function either returns a tuple of the root it found and the number of iterations or raises a `RuntimeError` if it did not converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_search(func, deriv, guess, epsilon=1e-15, max_iter=1000):\n",
    "    n_iter = ...  # track the number of iterations (1)\n",
    "\n",
    "    # Iterate until the guess is good enough\n",
    "    # or the maximum number of iterations are reached\n",
    "    while (...) and (...):  # copy the stopping criterion from show_search()\n",
    "                            # and add a check that no more than max_iter iterations can happen\n",
    "\n",
    "        ...  # update the number of iterations (2)\n",
    "\n",
    "        ...  # update the current best guess\n",
    "\n",
    "    # If the search procedure did not converge\n",
    "    if n_iter == max_iter:\n",
    "        raise RuntimeError(\"Local search did not converge!\")\n",
    "\n",
    "    return guess, ...  # complete the return value according to the description above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton's Method is very robust with respect to the initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search(f1, df1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search(f1, df1, -1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search(f1, df1, -1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search(f1, df1, -1_000_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search(f1, df1, -1_000_000_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By allowing less fault tolerance `epsilon`, the search procedure does not converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search(f1, df1, -1_000_000_000_000, epsilon=1e-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even starting around flat line segments works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search(f1, df1, -0.5773)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search(f1, df1, -0.577350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search(f1, df1, -0.57735026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search(f1, df1, -0.5773502691)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search(f1, df1, -0.577350269189)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, plugging in the exact $x$ value of a local maximum or minimum causes troubles. Here, we use $x_0 = -\\sqrt{\\frac{1}{3}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_search(f1, df1, -(1/3) ** (1/2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can avoid a crashing `local_search()` by wrapping the function with another function `search()` that handles exceptions and re-calls `local_search()` repeatedly with a slightly different initial guess until the search converges. To avoid the possibility of another infinite loop we restrict this to `max_retries` tries defaulting to $10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(func, deriv, guess, epsilon=1e-15, max_iter=1000, max_retries=10):\n",
    "    for _ in range(max_retries):\n",
    "        try:\n",
    "            root, _ = ...  # call local_search() with the correct arguments\n",
    "        except ZeroDivisionError:\n",
    "            guess += random()\n",
    "        else:\n",
    "            return root\n",
    "    else:\n",
    "        raise RuntimeError(\"Local search did not converge repeatedly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Newton's Method even works with $x_0 = -\\sqrt{\\frac{1}{3}}$ as the initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search(f1, df1, -(1/3) ** (1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square Roots\n",
    "\n",
    "Finally, we implement our own `sqrt()` function that takes one mandatory argument `n` and an optional argument `guess` (defaulting to $0$) and calculates the square root by calling `search()` with the correct `func` and `deriv` arguments.\n",
    "\n",
    "What are these correct arguments? Observe that a function $f_2(x) = x^2 - n$ has its roots where $x^2 = n$ and its derivative is $f'_2(x) = 2x$. That implies that $f_2$ depends on the number `n` that we want to find the square root of and we need to revert to the same trick as above with `create_tangent()` and use an outer function `create_f2()` that dynamically creates the `f2()` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_f2(n):\n",
    "    def f2(x):\n",
    "        return ...  # put in an arithmetic expression\n",
    "    return f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2(x):\n",
    "    return ...  # put in an arithmetic expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrt(n, guess=0):\n",
    "    f2 = ...  # call create_f2() with the correct argument\n",
    "    return search(f2, df2, guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate square roots without the `math` module in the Standard Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use two `lambda` expressions and formulate `sqrt()` compactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrt(n, guess=0):\n",
    "    return search(lambda x: ..., lambda x: ..., guess)  # put in the two arithmetic expressions from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
